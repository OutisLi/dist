(window.webpackJsonp=window.webpackJsonp||[]).push([[36],{319:function(t,s,a){"use strict";a.r(s);var n=a(14),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"_2024-02-28-2-5-fir-filter"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2024-02-28-2-5-fir-filter"}},[t._v("#")]),t._v(" 2024.02.28-2.5 FIR Filter")]),t._v(" "),s("p",[s("img",{attrs:{src:"2024%2002%2028-2%205%20FIR%20Filter%20ff2c573494664f2b81ff4c6f2e21bf80/Untitled.jpeg",alt:"Untitled"}})]),t._v(" "),s("p",[t._v("$$\ny[n] = b_0 x[n] + b_1 x[n-1] + b_2 x[n-2] + ...\n$$")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" My4ElementFir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b0"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b2"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b3"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" Module "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" io "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" IO"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Bundle "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" in "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Input"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("UInt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.")]),t._v("W"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" out "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Output"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("UInt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.")]),t._v("W"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" reg_1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RegInit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.")]),t._v("U"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.")]),t._v("W"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" reg_2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RegInit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.")]),t._v("U"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.")]),t._v("W"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" reg_3 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RegInit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.")]),t._v("U"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.")]),t._v("W"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  \n  reg_1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" io"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("in\n  reg_2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" reg_1\n  reg_3 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" reg_2\n\n\t"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 或者使用RegNext来一并定义初始化及赋值")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" reg_1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RegNext"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("io"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("in"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.")]),t._v("U"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" reg_2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RegNext"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("reg_1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.")]),t._v("U"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" reg_3 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RegNext"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("reg_2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.")]),t._v("U"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  \n  io"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("U"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.")]),t._v("W"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" io"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("in "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" b1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("U"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.")]),t._v("W"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" reg_1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" b2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("U"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.")]),t._v("W"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" reg_2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" b3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("U"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.")]),t._v("W"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" reg_3\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("h2",{attrs:{id:"fir-filter-generator"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#fir-filter-generator"}},[t._v("#")]),t._v(" "),s("strong",[t._v("FIR Filter Generator")])]),t._v(" "),s("p",[t._v("一个有限脉冲响应（FIR）滤波器生成器。生成器的**"),s("code",[t._v("length")]),s("strong",[t._v("参数决定了滤波器的抽头数目，即滤波器的长度。这个生成器有三个输入：")]),s("code",[t._v("in")]),s("strong",[t._v("（滤波器的输入信号）、")]),s("code",[t._v("valid")]),s("strong",[t._v("（一个布尔值，表示输入是否有效）和")]),s("code",[t._v("consts")]),s("strong",[t._v("（一个向量，包含所有抽头的系数）。还有一个输出")]),s("code",[t._v("out")]),t._v("**，即滤波器的输出。")]),t._v(" "),s("ul",[s("li",[t._v("**"),s("code",[t._v("taps")]),t._v("**是一个序列，包含输入和一系列寄存器，用于实现滤波器的延迟线。")]),t._v(" "),s("li",[t._v("当**"),s("code",[t._v("valid")]),t._v("**信号为真时，序列中的每个元素（除了第一个）被更新为前一个元素的值。")]),t._v(" "),s("li",[t._v("输出**"),s("code",[t._v("out")]),t._v("**是抽头值和对应系数乘积之和。")])]),t._v(" "),s("p",[t._v("这个结构允许滤波器动态处理不同长度的输入，通过改变**"),s("code",[t._v("consts")]),t._v("**向量的内容来改变滤波器的特性。")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" MyManyDynamicElementVecFir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("length"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" Module "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" io "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" IO"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Bundle "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" in "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Input"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("UInt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.")]),t._v("W"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" valid "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Input"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Bool"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" out "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Output"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("UInt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.")]),t._v("W"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" consts "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Input"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Vec"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" UInt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.")]),t._v("W"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  \n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Such concision! You'll learn what all this means later.")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" taps "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Seq"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("io"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("in"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v(" Seq"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fill"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("io"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("consts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RegInit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.")]),t._v("U"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.")]),t._v("W"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  taps"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("zip"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("taps"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tail"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" when "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("io"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("valid"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" a "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  io"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" taps"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("zip"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("io"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("consts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" a "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduce"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_ "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" _"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nvisualize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" MyManyDynamicElementVecFir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("ol",[s("li",[s("p",[s("strong",[s("code",[t._v("val io = IO(new Bundle {...})")]),s("strong",[t._v("定义了模块的接口，包括8位宽的输入")]),s("code",[t._v("in")])]),t._v("，一个有效信号**"),s("code",[t._v("valid")]),s("strong",[t._v("，8位宽输出")]),s("code",[t._v("out")]),s("strong",[t._v("，和长度为")]),s("code",[t._v("length")]),s("strong",[t._v("的系数向量")]),s("code",[t._v("consts")]),t._v("**。")])]),t._v(" "),s("li",[s("p",[t._v("**"),s("code",[t._v("val taps = Seq(io.in) ++ Seq.fill(io.consts.length - 1)(RegInit(0.U(8.W)))")]),s("strong",[t._v("这行代码在FIR滤波器实现中创建了一个名为")]),s("code",[t._v("taps")]),s("strong",[t._v("的序列，用于存储当前和之前的输入值，从而实现数据的时间序列延迟。首先，它将输入信号")]),s("code",[t._v("io.in")]),s("strong",[t._v("作为序列的第一个元素。随后，使用")]),s("code",[t._v("++")]),s("strong",[t._v("操作符将")]),s("code",[t._v("io.in")]),s("strong",[t._v("与一个新的序列连接起来，后者通过")]),s("code",[t._v("Seq.fill(io.consts.length - 1)(RegInit(0.U(8.W)))")]),s("strong",[t._v("创建，其中包含")]),s("code",[t._v("length - 1")]),s("strong",[t._v("个初始化为0的8位寄存器。这样，")]),s("code",[t._v("taps")]),s("strong",[t._v("序列就包含了一个输入信号和")]),s("code",[t._v("length - 1")]),s("strong",[t._v("个延迟寄存器，总共")]),s("code",[t._v("length")]),s("strong",[t._v("个元素，每个元素对应滤波器的一个抽头。在Chisel中，虽然")]),s("code",[t._v("io.in")]),s("strong",[t._v("不是寄存器，但")]),s("code",[t._v("taps")]),s("strong",[t._v("序列可以包含不同类型的元素，因为在Chisel里，所有这些都被视为")]),s("code",[t._v("Data")]),s("strong",[t._v("类型的子类，可以被综合为硬件。在这个上下文中，")]),s("code",[t._v("io.in")]),t._v("**是直接的输入信号，而后续元素是寄存器类型，但它们共同构成了一个序列，用于表示滤波器的不同时间点上的信号值。这种混合类型的序列是可行的，并可以在Chisel生成的硬件中正确表达相应的逻辑。")])]),t._v(" "),s("li",[s("p",[t._v("**"),s("code",[t._v("taps.zip(taps.tail).foreach { case (a, b) => when (io.valid) { b := a } }")]),s("strong",[t._v("在输入")]),s("code",[t._v("valid")]),s("strong",[t._v("为真时，将")]),s("code",[t._v("taps")]),t._v("**序列中每个元素的值传递到下一个元素，实现数据在寄存器间的移动。")]),t._v(" "),s("p",[s("strong",[s("code",[t._v("zip")]),s("strong",[t._v("是一个方法，它将两个集合中对应位置的元素组成一对，生成一个新的集合。在这里，")]),s("code",[t._v("taps.zip(taps.tail)")]),s("strong",[t._v("的作用是将")]),s("code",[t._v("taps")]),s("strong",[t._v("列表中的每个元素与其后面的元素配对。")]),s("code",[t._v("tail")]),s("strong",[t._v("是一个方法，返回除第一个元素外的列表所有元素。例如，如果")]),s("code",[t._v("taps")]),s("strong",[t._v("是")]),s("code",[t._v("[in, reg1, reg2, reg3]")])]),t._v("，那么**"),s("code",[t._v("taps.tail")]),s("strong",[t._v("就是")]),s("code",[t._v("[reg1, reg2, reg3]")]),s("strong",[t._v("。")]),s("code",[t._v("taps.zip(taps.tail)")]),s("strong",[t._v("的结果将是")]),s("code",[t._v("[(in, reg1), (reg1, reg2), (reg2, reg3)]")]),s("strong",[t._v("。这样，")]),s("code",[t._v("foreach")]),s("strong",[t._v("就可以遍历这些配对，根据")]),s("code",[t._v("valid")]),t._v("**信号更新寄存器的值，实现数据的逐级传递。")]),t._v(" "),s("p",[s("strong",[s("code",[t._v("case (a, b) =>")]),s("strong",[t._v("是模式匹配的语法，用于解构元组，将")]),s("code",[t._v("zip")]),s("strong",[t._v("操作生成的元素对分别赋值给")]),s("code",[t._v("a")])]),t._v("（当前元素）和**"),s("code",[t._v("b")]),t._v("**（下一个元素）。")])]),t._v(" "),s("li",[s("p",[s("strong",[s("code",[t._v("io.out := taps.zip(io.consts).map { case (a, b) => a * b }.reduce(_ + _)")]),s("strong",[t._v("计算输出")]),s("code",[t._v("out")])]),t._v("，即将每个延迟元素与其对应的系数相乘，并将所有乘积求和得到最终结果。")]),t._v(" "),s("p",[t._v("在这段代码中，**"),s("code",[t._v("map")]),s("strong",[t._v("和")]),s("code",[t._v("reduce")]),t._v("**是Scala中的集合操作方法：")]),t._v(" "),s("ul",[s("li",[s("strong",[s("code",[t._v("map")])]),t._v("：对集合中的每个元素应用一个函数。这里**"),s("code",[t._v("map { case (a, b) => a * b }")]),s("strong",[t._v("对每对")]),s("code",[t._v("(a, b)")]),s("strong",[t._v("应用乘法操作，")]),s("code",[t._v("a")]),s("strong",[t._v("来自")]),s("code",[t._v("taps")]),s("strong",[t._v("，")]),s("code",[t._v("b")]),s("strong",[t._v("来自")]),s("code",[t._v("io.consts")]),t._v("**，分别代表寄存器中的数据和滤波器的系数。")]),t._v(" "),s("li",[s("strong",[s("code",[t._v("reduce")])]),t._v("：对集合中的元素应用一个二元操作，逐步将集合减少为单一结果。这里的**"),s("code",[t._v("reduce(_ + _)")]),t._v("**将所有乘法结果相加，得到最终的滤波输出。")])]),t._v(" "),s("p",[t._v("不使用**"),s("code",[t._v("foreach")]),s("strong",[t._v("是因为")]),s("code",[t._v("foreach")]),s("strong",[t._v("仅用于执行操作而不返回结果，而这里的目的是计算经过滤波器后的输出值，需要通过")]),s("code",[t._v("map")]),s("strong",[t._v("和")]),s("code",[t._v("reduce")]),t._v("**聚合计算结果。")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);